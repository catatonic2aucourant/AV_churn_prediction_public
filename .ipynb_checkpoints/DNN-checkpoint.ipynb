{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "\n",
    "import category_encoders as en\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, make_union\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Reshape\n",
    "from keras.layers import Input, concatenate, BatchNormalization\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, Callback\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_features(X):\n",
    "    X_list = []\n",
    "    \n",
    "    cols = [user_feats, acc_feats, invest_feats, misc_feats, percent_feats, balance_feats,\n",
    "                      new_feats, C_prev, D_prev, all_credit, all_debit, custint_credit, custint_debit,\n",
    "                      cashwithdraw, cashdeposit, cnr, bal, eop, cr_amb, atm_amt]\n",
    "    \n",
    "    for col in cols:\n",
    "        X_list.append(X[col].values)\n",
    "    \n",
    "    return X_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class roc_auc_callback(Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(split_features(self.x), verbose=0)\n",
    "        roc = roc_auc_score(self.y, y_pred)\n",
    "        logs['roc_auc'] = roc_auc_score(self.y, y_pred)\n",
    "        logs['norm_gini'] = ( roc_auc_score(self.y, y_pred) * 2 ) - 1\n",
    "\n",
    "        y_pred_val = self.model.predict(split_features(self.x_val), verbose=0)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        logs['roc_auc_val'] = roc_auc_score(self.y_val, y_pred_val)\n",
    "        logs['norm_gini_val'] = ( roc_auc_score(self.y_val, y_pred_val) * 2 ) - 1\n",
    "\n",
    "        print('\\rroc_auc: %s - roc_auc_val: %s - norm_gini: %s - norm_gini_val: %s' % (str(round(roc,5)),str(round(roc_val,5)),str(round((roc*2-1),5)),str(round((roc_val*2-1),5))), end=10*' '+'\\n')\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod(\n",
    "            (datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' %\n",
    "              (thour, tmin, round(tsec, 2)))\n",
    "\n",
    "def scale_data(X, scaler=None):\n",
    "    if not scaler:\n",
    "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train and test data path\n",
    "DATA_TRAIN_PATH = '../utility/train_wfeats2.csv'\n",
    "DATA_TEST_PATH = '../utility/test_wfeats2.csv'\n",
    "\n",
    "def load_data(path_train=DATA_TRAIN_PATH, path_test=DATA_TEST_PATH):\n",
    "    train_loader = pd.read_csv(path_train, dtype={'Responders': np.int8, 'UCIC_ID': np.int32})\n",
    "    train = train_loader.drop(['Responders', 'UCIC_ID'], axis=1)\n",
    "    train_labels = train_loader['Responders'].values\n",
    "    train_ids = train_loader['UCIC_ID'].values\n",
    "    print('\\n Shape of raw train data:', train.shape)\n",
    "\n",
    "    test_loader = pd.read_csv(path_test, dtype={'UCIC_ID': np.int32})\n",
    "    test = test_loader.drop(['UCIC_ID'], axis=1)\n",
    "    test_ids = test_loader['UCIC_ID'].values\n",
    "    print(' Shape of raw test data:', test.shape)\n",
    "\n",
    "    return train, train_labels, test, train_ids, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds = 5\n",
    "runs = 3\n",
    "\n",
    "cv_LL = 0\n",
    "cv_AUC = 0\n",
    "cv_gini = 0\n",
    "fpred = []\n",
    "avpred = []\n",
    "avreal = []\n",
    "avids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Shape of raw train data: (300000, 424)\n",
      " Shape of raw test data: (200000, 425)\n",
      "\n",
      " Shape of processed train data: (300000, 338)\n",
      " Shape of processed test data: (200000, 339)\n"
     ]
    }
   ],
   "source": [
    "train, target, test, tr_ids, te_ids = load_data()\n",
    "\n",
    "#Lets drop calc columns (why?)\n",
    "useless_cols = [col for col in train.columns if train[col].var() < 0.001]\n",
    "train.drop(useless_cols, axis=1, inplace=True)\n",
    "test.drop(useless_cols, axis=1, inplace=True)\n",
    "\n",
    "n_train = train.shape[0]\n",
    "\n",
    "#Lets treat -1 as separate label and convert categoricals to one hot encoding for neural network\n",
    "#cat_cols = [col for col in train.columns if 'cat' in col]\n",
    "#not_cat_cols = [col for col in train.columns if col not in cat_cols]\n",
    "\n",
    "#train_test = pd.concat((train, test)).reset_index(drop=True)\n",
    "\n",
    "#train_test_noncat = train_test[not_cat_cols]\n",
    "#train_test_cat = train_test[cat_cols]\n",
    "\n",
    "#First lets do label encoding to get rid of -1 (causes problems with one hot encoding)\n",
    "#for col in cat_cols:\n",
    "#    lb = LabelEncoder()\n",
    "#    lb.fit(train_test_cat[col]) #Fit on all data \n",
    "#    train_test_cat[col] = lb.transform(train_test_cat[col]) + 1\n",
    "    #train[col] = lb.transform(train[col]) + 1  #Keras embedding layer needs labels starting 1\n",
    "    #test[col]  = lb.transform(test[col]) + 1   #Keras embedding layer needs labels starting 1\n",
    "    \n",
    "#print(\"Unique values in each of caterical column\", train[cat_cols].apply(lambda x: x.nunique()))\n",
    "\n",
    "#train_test_noncat = train_test[not_cat_cols]\n",
    "#train_test_noncat_scaled, scaler = scale_data(train_test_noncat)\n",
    "\n",
    "#train_test_noncat_scaled = pd.DataFrame(train_test_noncat_scaled, columns=not_cat_cols)\n",
    "\n",
    "## After scaling and label encoding\n",
    "#train_test = pd.concat([train_test_noncat_scaled,train_test_cat], axis=1)\n",
    "\n",
    "#train = train_test.loc[:(n_train-1), :]\n",
    "#test = train_test.loc[n_train:, :]\n",
    "\n",
    "#train_test_scaled, scaler = scale_data(train_test)\n",
    "\n",
    "#train = train_test_scaled[:n_train, :]\n",
    "#test = train_test_scaled[n_train:, :]\n",
    "\n",
    "#n_train = train.shape[0]\n",
    "#train_test = pd.concat((train, test)).reset_index(drop=True)\n",
    "#col_to_drop = train.columns[train.columns.str.endswith('_cat')]\n",
    "#col_to_dummify = train.columns[train.columns.str.endswith('_cat')].astype(str).tolist()\n",
    "\n",
    "#for col in col_to_dummify:\n",
    "#    dummy = pd.get_dummies(train_test[col].astype('category'))\n",
    "#    columns = dummy.columns.astype(str).tolist()\n",
    "#    columns = [col + '_' + w for w in columns]\n",
    "#    dummy.columns = columns\n",
    "#    train_test = pd.concat((train_test, dummy), axis=1)\n",
    "\n",
    "#train_test.drop(col_to_dummify, axis=1, inplace=True)\n",
    "#train_test_scaled, scaler = scale_data(train_test)\n",
    "#train = train_test_scaled[:n_train, :]\n",
    "#test = train_test_scaled[n_train:, :]\n",
    "print('\\n Shape of processed train data:', train.shape)\n",
    "print(' Shape of processed test data:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NO_OF_Accs', 'vintage', 'dependents', 'zip', 'C_prev1', 'D_prev1',\n",
       "       'ATM_D_prev1', 'BRANCH_C_prev1', 'BRANCH_D_prev1', 'IB_C_prev1',\n",
       "       'IB_D_prev1', 'POS_D_prev1', 'count_C_prev1', 'count_D_prev1',\n",
       "       'COUNT_ATM_D_prev1', 'COUNT_BRANCH_C_prev1', 'COUNT_BRANCH_D_prev1',\n",
       "       'COUNT_IB_C_prev1', 'COUNT_IB_D_prev1', 'COUNT_MB_D_prev1',\n",
       "       'COUNT_POS_D_prev1', 'custinit_CR_amt_prev1',\n",
       "       'custinit_DR_amt_prev1', 'custinit_CR_cnt_prev1',\n",
       "       'custinit_DR_cnt_prev1', 'ATM_amt_prev1', 'ATM_CW_Amt_prev1',\n",
       "       'ATM_CW_Cnt_prev1', 'BRN_CW_Amt_prev1', 'BRN_CW_Cnt_prev1',\n",
       "       'BRN_CASH_Dep_Amt_prev1', 'BRN_CASH_Dep_Cnt_prev1', 'CNR_prev1',\n",
       "       'BAL_prev1', 'EOP_prev1', 'CR_AMB_Prev1', 'C_prev2', 'D_prev2',\n",
       "       'ATM_D_prev2', 'BRANCH_C_prev2', 'BRANCH_D_prev2', 'IB_C_prev2',\n",
       "       'IB_D_prev2', 'POS_D_prev2', 'count_C_prev2', 'count_D_prev2',\n",
       "       'COUNT_ATM_D_prev2', 'COUNT_BRANCH_C_prev2', 'COUNT_BRANCH_D_prev2',\n",
       "       'COUNT_IB_C_prev2', 'COUNT_IB_D_prev2', 'COUNT_MB_D_prev2',\n",
       "       'COUNT_POS_D_prev2', 'custinit_CR_amt_prev2',\n",
       "       'custinit_DR_amt_prev2', 'custinit_CR_cnt_prev2',\n",
       "       'custinit_DR_cnt_prev2', 'ATM_amt_prev2', 'ATM_CW_Amt_prev2',\n",
       "       'ATM_CW_Cnt_prev2', 'BRN_CW_Amt_prev2', 'BRN_CW_Cnt_prev2',\n",
       "       'BRN_CASH_Dep_Amt_prev2', 'BRN_CASH_Dep_Cnt_prev2', 'CNR_prev2',\n",
       "       'BAL_prev2', 'EOP_prev2', 'CR_AMB_Prev2', 'C_prev3', 'D_prev3',\n",
       "       'ATM_D_prev3', 'BRANCH_C_prev3', 'BRANCH_D_prev3', 'IB_C_prev3',\n",
       "       'IB_D_prev3', 'POS_D_prev3', 'count_C_prev3', 'count_D_prev3',\n",
       "       'COUNT_ATM_D_prev3', 'COUNT_BRANCH_C_prev3', 'COUNT_BRANCH_D_prev3',\n",
       "       'COUNT_IB_C_prev3', 'COUNT_IB_D_prev3', 'COUNT_MB_D_prev3',\n",
       "       'COUNT_POS_D_prev3', 'custinit_CR_amt_prev3',\n",
       "       'custinit_DR_amt_prev3', 'custinit_CR_cnt_prev3',\n",
       "       'custinit_DR_cnt_prev3', 'ATM_amt_prev3', 'ATM_CW_Amt_prev3',\n",
       "       'ATM_CW_Cnt_prev3', 'BRN_CW_Amt_prev3', 'BRN_CW_Cnt_prev3',\n",
       "       'BRN_CASH_Dep_Amt_prev3', 'BRN_CASH_Dep_Cnt_prev3', 'CNR_prev3',\n",
       "       'BAL_prev3', 'EOP_prev3', 'CR_AMB_Prev3', 'C_prev4', 'D_prev4',\n",
       "       'ATM_D_prev4', 'BRANCH_C_prev4', 'BRANCH_D_prev4', 'IB_C_prev4',\n",
       "       'IB_D_prev4', 'POS_D_prev4', 'count_C_prev4', 'count_D_prev4',\n",
       "       'COUNT_ATM_D_prev4', 'COUNT_BRANCH_C_prev4', 'COUNT_BRANCH_D_prev4',\n",
       "       'COUNT_IB_C_prev4', 'COUNT_IB_D_prev4', 'COUNT_MB_D_prev4',\n",
       "       'COUNT_POS_D_prev4', 'custinit_CR_amt_prev4',\n",
       "       'custinit_DR_amt_prev4', 'custinit_CR_cnt_prev4',\n",
       "       'custinit_DR_cnt_prev4', 'ATM_amt_prev4', 'ATM_CW_Amt_prev4',\n",
       "       'ATM_CW_Cnt_prev4', 'BRN_CW_Amt_prev4', 'BRN_CW_Cnt_prev4',\n",
       "       'BRN_CASH_Dep_Amt_prev4', 'BRN_CASH_Dep_Cnt_prev4', 'CNR_prev4',\n",
       "       'BAL_prev4', 'EOP_prev4', 'CR_AMB_Prev4', 'C_prev5', 'D_prev5',\n",
       "       'ATM_D_prev5', 'BRANCH_C_prev5', 'BRANCH_D_prev5', 'IB_C_prev5',\n",
       "       'IB_D_prev5', 'POS_D_prev5', 'count_C_prev5', 'count_D_prev5',\n",
       "       'COUNT_ATM_D_prev5', 'COUNT_BRANCH_C_prev5', 'COUNT_BRANCH_D_prev5',\n",
       "       'COUNT_IB_C_prev5', 'COUNT_IB_D_prev5', 'COUNT_MB_D_prev5',\n",
       "       'COUNT_POS_D_prev5', 'custinit_CR_amt_prev5',\n",
       "       'custinit_DR_amt_prev5', 'custinit_CR_cnt_prev5',\n",
       "       'custinit_DR_cnt_prev5', 'ATM_amt_prev5', 'ATM_CW_Amt_prev5',\n",
       "       'ATM_CW_Cnt_prev5', 'BRN_CW_Amt_prev5', 'BRN_CW_Cnt_prev5',\n",
       "       'BRN_CASH_Dep_Amt_prev5', 'BRN_CASH_Dep_Cnt_prev5', 'CNR_prev5',\n",
       "       'BAL_prev5', 'EOP_prev5', 'CR_AMB_Prev5', 'C_prev6', 'D_prev6',\n",
       "       'ATM_D_prev6', 'BRANCH_C_prev6', 'BRANCH_D_prev6', 'IB_C_prev6',\n",
       "       'IB_D_prev6', 'POS_D_prev6', 'count_C_prev6', 'count_D_prev6',\n",
       "       'COUNT_ATM_D_prev6', 'COUNT_BRANCH_C_prev6', 'COUNT_BRANCH_D_prev6',\n",
       "       'COUNT_IB_C_prev6', 'COUNT_IB_D_prev6', 'COUNT_MB_D_prev6',\n",
       "       'COUNT_POS_D_prev6', 'custinit_CR_amt_prev6',\n",
       "       'custinit_DR_amt_prev6', 'custinit_CR_cnt_prev6',\n",
       "       'custinit_DR_cnt_prev6', 'ATM_amt_prev6', 'ATM_CW_Amt_prev6',\n",
       "       'ATM_CW_Cnt_prev6', 'BRN_CW_Amt_prev6', 'BRN_CW_Cnt_prev6',\n",
       "       'BRN_CASH_Dep_Amt_prev6', 'BRN_CASH_Dep_Cnt_prev6', 'CNR_prev6',\n",
       "       'BAL_prev6', 'EOP_prev6', 'CR_AMB_Prev6', 'Billpay_Active_PrevQ1',\n",
       "       'Billpay_Reg_ason_Prev1', 'FD_AMOUNT_BOOK_PrevQ1',\n",
       "       'FD_AMOUNT_BOOK_PrevQ2', 'NO_OF_FD_BOOK_PrevQ1',\n",
       "       'NO_OF_FD_BOOK_PrevQ2', 'NO_OF_RD_BOOK_PrevQ1',\n",
       "       'NO_OF_RD_BOOK_PrevQ2', 'RD_AMOUNT_BOOK_PrevQ1',\n",
       "       'RD_AMOUNT_BOOK_PrevQ2', 'Total_Invest_in_MF_PrevQ1',\n",
       "       'Total_Invest_in_MF_PrevQ2', 'count_No_of_MF_PrevQ1',\n",
       "       'count_No_of_MF_PrevQ2', 'Dmat_Investing_PrevQ1',\n",
       "       'Dmat_Investing_PrevQ2', 'AL_PREM_CLOSED_PREVQ1',\n",
       "       'OTHER_LOANS_PREM_CLOSED_PREVQ1', 'RD_PREM_CLOSED_PREVQ1',\n",
       "       'FD_PREM_CLOSED_PREVQ1', 'AL_Closed_PrevQ1', 'CC_CLOSED_PREVQ1',\n",
       "       'OTHER_LOANS_Closed_PrevQ1', 'RD_CLOSED_PREVQ1', 'FD_CLOSED_PREVQ1',\n",
       "       'DEMAT_CLOSED_PREV1YR', 'SEC_ACC_CLOSED_PREV1YR', 'AL_CNC_DATE',\n",
       "       'AL_DATE', 'BL_DATE', 'CE_DATE', 'CV_DATE', 'GL_DATE', 'LAP_DATE',\n",
       "       'OTHER_LOANS_DATE', 'PL_DATE', 'TWL_DATE', 'Charges_PrevQ1',\n",
       "       'Charges_cnt_PrevQ1', 'NO_OF_COMPLAINTS', 'CASH_WD_AMT_Last6',\n",
       "       'CASH_WD_CNT_Last6', 'brn_code', 'age', 'Recency_of_CR_TXN',\n",
       "       'Recency_of_DR_TXN', 'Recency_of_IB_TXN', 'Recency_of_ATM_TXN',\n",
       "       'Recency_of_BRANCH_TXN', 'Recency_of_POS_TXN', 'Recency_of_MB_TXN',\n",
       "       'Recency_of_Activity', 'I_AQB_PrevQ1', 'I_AQB_PrevQ2',\n",
       "       'I_CR_AQB_PrevQ1', 'I_CR_AQB_PrevQ2', 'I_CNR_PrevQ1',\n",
       "       'I_CNR_PrevQ2', 'I_NRV_PrevQ1', 'I_NRV_PrevQ2',\n",
       "       'CR_AMB_Drop_Build_1', 'CR_AMB_Drop_Build_2', 'CR_AMB_Drop_Build_3',\n",
       "       'CR_AMB_Drop_Build_4', 'CR_AMB_Drop_Build_5', 'Req_Logged_PrevQ1',\n",
       "       'Query_Logged_PrevQ1', 'NO_OF_CHEQUE_BOUNCE_V1',\n",
       "       'Percent_Change_in_Credits', 'Percent_Change_in_FT_Bank',\n",
       "       'Percent_Change_in_FT_outside', 'Percent_Change_in_Self_Txn',\n",
       "       'Percent_Change_in_Big_Expenses', 'HNW_CATEGORY',\n",
       "       'EMAIL_UNSUBSCRIBE', 'OCCUP_ALL_NEW', 'city', 'FINAL_WORTH_prev1',\n",
       "       'ENGAGEMENT_TAG_prev1', 'EFT_SELF_TRANSFER_PrevQ1',\n",
       "       'AL_CNC_TAG_LIVE', 'AL_TAG_LIVE', 'BL_TAG_LIVE', 'CC_TAG_LIVE',\n",
       "       'CV_TAG_LIVE', 'DEMAT_TAG_LIVE', 'GL_TAG_LIVE', 'HL_TAG_LIVE',\n",
       "       'SEC_ACC_TAG_LIVE', 'INS_TAG_LIVE', 'MF_TAG_LIVE',\n",
       "       'OTHER_LOANS_TAG_LIVE', 'PL_TAG_LIVE', 'RD_TAG_LIVE', 'FD_TAG_LIVE',\n",
       "       'TWL_TAG_LIVE', 'lap_tag_live', 'Billpay_Active_PrevQ1_N',\n",
       "       'Billpay_Reg_ason_Prev1_N', 'Charges_cnt_PrevQ1_N',\n",
       "       'RBI_Class_Audit', 'gender_bin', 'Req_Resolved_PrevQ1',\n",
       "       'Query_Resolved_PrevQ1', 'Complaint_Resolved_PrevQ1',\n",
       "       'FINAL_WORTH_prev1_likelihood', 'zip_likelihood',\n",
       "       'brn_code_likelihood', 'EOB_rat1qcut_likelihood',\n",
       "       'EOB_prev1qcut_likelihood', 'CR_mean_drop', 'CR_std_drop',\n",
       "       'EOP_mean_drop', 'EOP_std_drop', 'CR_sum_drop', 'EOB_rat1',\n",
       "       'bal_rats', 'EOP_prev1log', 'brn_bal', 'zip_bal', 'bal_decline6',\n",
       "       'bal_decline5', 'bal_decline5.1', 'bal_decline3', 'bal_decline2',\n",
       "       'EOB_rat2', 'CR_rat2', 'debits_std', 'debits_mean', 'debit1_rat',\n",
       "       'EOB_rat1qcut', 'EOB_prev1qcut', 'acc_prem_close',\n",
       "       'acc_prem_close_sum', 'loan_close_num', 'growth_close_num',\n",
       "       'loan_flag_sum1', 'loan_flag_sum2', 'FD_amt_diff', 'DM_amt_diff',\n",
       "       'MF_amt_diff', 'FD_Q1_Q2_diffabs'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "14\n",
      "38\n",
      "20\n",
      "4\n",
      "8\n",
      "37\n",
      "12 12\n",
      "24\n",
      "54\n",
      "12\n",
      "12\n",
      "24\n",
      "12\n",
      "6\n",
      "6\n",
      "6\n",
      "11\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "user_feats = ['NO_OF_Accs', 'vintage', 'dependents', 'zip', 'HNW_CATEGORY',\n",
    "       'EMAIL_UNSUBSCRIBE', 'OCCUP_ALL_NEW', 'city', 'gender_bin', 'Billpay_Active_PrevQ1',\n",
    "       'Billpay_Reg_ason_Prev1', 'brn_code', 'age', 'ENGAGEMENT_TAG_prev1', 'EFT_SELF_TRANSFER_PrevQ1']\n",
    "print(len(user_feats))\n",
    "\n",
    "invest_feats = ['FD_AMOUNT_BOOK_PrevQ1',\n",
    "       'FD_AMOUNT_BOOK_PrevQ2', 'NO_OF_FD_BOOK_PrevQ1',\n",
    "       'NO_OF_FD_BOOK_PrevQ2', 'NO_OF_RD_BOOK_PrevQ1',\n",
    "       'NO_OF_RD_BOOK_PrevQ2', 'RD_AMOUNT_BOOK_PrevQ1',\n",
    "       'RD_AMOUNT_BOOK_PrevQ2', 'Total_Invest_in_MF_PrevQ1',\n",
    "       'Total_Invest_in_MF_PrevQ2', 'count_No_of_MF_PrevQ1',\n",
    "       'count_No_of_MF_PrevQ2', 'Dmat_Investing_PrevQ1',\n",
    "       'Dmat_Investing_PrevQ2']\n",
    "print(len(invest_feats))\n",
    "\n",
    "acc_feats = ['AL_PREM_CLOSED_PREVQ1',\n",
    "       'OTHER_LOANS_PREM_CLOSED_PREVQ1', 'RD_PREM_CLOSED_PREVQ1',\n",
    "       'FD_PREM_CLOSED_PREVQ1', 'AL_Closed_PrevQ1', 'CC_CLOSED_PREVQ1',\n",
    "       'OTHER_LOANS_Closed_PrevQ1', 'RD_CLOSED_PREVQ1', 'FD_CLOSED_PREVQ1',\n",
    "       'DEMAT_CLOSED_PREV1YR', 'SEC_ACC_CLOSED_PREV1YR', 'AL_CNC_DATE',\n",
    "       'AL_DATE', 'BL_DATE', 'CE_DATE', 'CV_DATE', 'GL_DATE', 'LAP_DATE',\n",
    "       'OTHER_LOANS_DATE', 'PL_DATE', 'TWL_DATE','AL_CNC_TAG_LIVE', 'AL_TAG_LIVE', 'BL_TAG_LIVE', 'CC_TAG_LIVE',\n",
    "       'CV_TAG_LIVE', 'DEMAT_TAG_LIVE', 'GL_TAG_LIVE', 'HL_TAG_LIVE',\n",
    "       'SEC_ACC_TAG_LIVE', 'INS_TAG_LIVE', 'MF_TAG_LIVE',\n",
    "       'OTHER_LOANS_TAG_LIVE', 'PL_TAG_LIVE', 'RD_TAG_LIVE', 'FD_TAG_LIVE',\n",
    "       'TWL_TAG_LIVE', 'lap_tag_live']\n",
    "print(len(acc_feats))\n",
    "\n",
    "misc_feats = ['Charges_PrevQ1',\n",
    "       'Charges_cnt_PrevQ1', 'NO_OF_COMPLAINTS', 'CASH_WD_AMT_Last6',\n",
    "       'CASH_WD_CNT_Last6','Recency_of_CR_TXN',\n",
    "       'Recency_of_DR_TXN', 'Recency_of_IB_TXN', 'Recency_of_ATM_TXN',\n",
    "       'Recency_of_BRANCH_TXN', 'Recency_of_POS_TXN', 'Recency_of_MB_TXN',\n",
    "       'Recency_of_Activity','Req_Logged_PrevQ1',\n",
    "       'Query_Logged_PrevQ1', 'NO_OF_CHEQUE_BOUNCE_V1','RBI_Class_Audit',\n",
    "             'Req_Resolved_PrevQ1',\n",
    "       'Query_Resolved_PrevQ1', 'Complaint_Resolved_PrevQ1']\n",
    "print(len(misc_feats))\n",
    "\n",
    "percent_feats = ['Percent_Change_in_FT_Bank',\n",
    "       'Percent_Change_in_FT_outside', 'Percent_Change_in_Self_Txn',\n",
    "       'Percent_Change_in_Big_Expenses']\n",
    "print(len(percent_feats))\n",
    "\n",
    "balance_feats = ['I_AQB_PrevQ1', 'I_AQB_PrevQ2',\n",
    "       'I_CR_AQB_PrevQ1', 'I_CR_AQB_PrevQ2', 'I_CNR_PrevQ1',\n",
    "       'I_CNR_PrevQ2', 'I_NRV_PrevQ1', 'I_NRV_PrevQ2',]\n",
    "print(len(balance_feats))\n",
    "\n",
    "new_feats = ['FINAL_WORTH_prev1_likelihood', 'zip_likelihood',\n",
    "       'brn_code_likelihood', 'EOB_rat1qcut_likelihood',\n",
    "       'EOB_prev1qcut_likelihood', 'CR_mean_drop', 'CR_std_drop',\n",
    "       'EOP_mean_drop', 'EOP_std_drop', 'CR_sum_drop', 'EOB_rat1',\n",
    "       'bal_rats', 'EOP_prev1log', 'brn_bal', 'zip_bal', 'bal_decline6',\n",
    "       'bal_decline5', 'bal_decline5.1', 'bal_decline3', 'bal_decline2',\n",
    "       'EOB_rat2', 'CR_rat2', 'debits_std', 'debits_mean', 'debit1_rat',\n",
    "       'EOB_rat1qcut', 'EOB_prev1qcut', 'acc_prem_close',\n",
    "       'acc_prem_close_sum', 'loan_close_num', 'growth_close_num',\n",
    "       'loan_flag_sum1', 'loan_flag_sum2', 'FD_amt_diff', 'DM_amt_diff',\n",
    "       'MF_amt_diff', 'FD_Q1_Q2_diffabs']\n",
    "print(len(new_feats))\n",
    "C_prev = train.filter(regex=\"(^C_prev?|^count_C_prev?)\").columns\n",
    "D_prev = train.filter(regex=\"(^C_prev?|^count_C_prev?)\").columns\n",
    "print(len(C_prev), len(D_prev))\n",
    "\n",
    "all_credit = train.filter(regex=\"^[A-Z_]{2,13}_C_prev?\").columns\n",
    "print(len(all_credit))\n",
    "\n",
    "all_debit = train.filter(regex=\"^[A-Z_]{2,13}_D_prev?\").columns\n",
    "print(len(all_debit))\n",
    "\n",
    "custint_credit = train.filter(regex=\"custinit_C\").columns\n",
    "print(len(custint_credit))\n",
    "\n",
    "custint_debit = train.filter(regex=\"custinit_D\").columns\n",
    "print(len(custint_debit))\n",
    "\n",
    "cashwithdraw = train.filter(regex=\"_CW_\").columns\n",
    "print(len(cashwithdraw))\n",
    "\n",
    "cashdeposit = train.filter(regex=\"CASH_Dep*\").columns\n",
    "print(len(cashdeposit))\n",
    "\n",
    "cnr = train.filter(regex=\"CNR_prev?\").columns\n",
    "print(len(cnr))\n",
    "\n",
    "bal = train.filter(regex=\"BAL_prev?\").columns\n",
    "print(len(bal))\n",
    "\n",
    "eop = train.filter(regex=\"EOP_prev[0-6]$\").columns\n",
    "print(len(eop))\n",
    "\n",
    "cr_amb = train.filter(regex=\"CR_AMB_?\").columns\n",
    "print(len(cr_amb))\n",
    "\n",
    "atm_amt = train.filter(regex='ATM_amt_').columns\n",
    "print(len(atm_amt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.fillna(0)\n",
    "test = test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80fbbd09ed004b12a7aaf48d25905051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold 1 - Run 1\n",
      "\n",
      "Train on 239999 samples, validate on 60001 samples\n",
      "Epoch 1/50\n",
      "roc_auc: 0.84176 - roc_auc_val: 0.84298 - norm_gini: 0.68353 - norm_gini_val: 0.68597          \n",
      "Epoch 00000: norm_gini_val improved from -inf to 0.68597, saving model to keras-5fold-run-01-v1-fold-01-run-01.check\n",
      "56s - loss: 0.3771 - val_loss: 0.3958\n",
      "Epoch 2/50\n",
      "roc_auc: 0.84683 - roc_auc_val: 0.84811 - norm_gini: 0.69367 - norm_gini_val: 0.69622          \n",
      "Epoch 00001: norm_gini_val improved from 0.68597 to 0.69622, saving model to keras-5fold-run-01-v1-fold-01-run-01.check\n",
      "52s - loss: 0.3327 - val_loss: 0.3662\n",
      "Epoch 3/50\n",
      "roc_auc: 0.85074 - roc_auc_val: 0.85165 - norm_gini: 0.70148 - norm_gini_val: 0.70329          \n",
      "Epoch 00002: norm_gini_val improved from 0.69622 to 0.70329, saving model to keras-5fold-run-01-v1-fold-01-run-01.check\n",
      "55s - loss: 0.3263 - val_loss: 0.3735\n",
      "Epoch 4/50\n",
      "roc_auc: 0.85025 - roc_auc_val: 0.85066 - norm_gini: 0.70049 - norm_gini_val: 0.70133          \n",
      "Epoch 00003: norm_gini_val did not improve\n",
      "52s - loss: 0.3244 - val_loss: 0.3787\n",
      "Epoch 5/50\n",
      "roc_auc: 0.85152 - roc_auc_val: 0.85171 - norm_gini: 0.70304 - norm_gini_val: 0.70343          \n",
      "Epoch 00004: norm_gini_val improved from 0.70329 to 0.70343, saving model to keras-5fold-run-01-v1-fold-01-run-01.check\n",
      "56s - loss: 0.3227 - val_loss: 0.3734\n",
      "Epoch 6/50\n",
      "roc_auc: 0.84889 - roc_auc_val: 0.84957 - norm_gini: 0.69779 - norm_gini_val: 0.69913          \n",
      "Epoch 00005: norm_gini_val did not improve\n",
      "56s - loss: 0.3211 - val_loss: 0.3803\n",
      "Epoch 7/50\n",
      "roc_auc: 0.85261 - roc_auc_val: 0.85251 - norm_gini: 0.70523 - norm_gini_val: 0.70502          \n",
      "Epoch 00006: norm_gini_val improved from 0.70343 to 0.70502, saving model to keras-5fold-run-01-v1-fold-01-run-01.check\n",
      "63s - loss: 0.3198 - val_loss: 0.3809\n",
      "Epoch 8/50\n",
      "roc_auc: 0.8528 - roc_auc_val: 0.85274 - norm_gini: 0.7056 - norm_gini_val: 0.70548          \n",
      "Epoch 00007: norm_gini_val improved from 0.70502 to 0.70548, saving model to keras-5fold-run-01-v1-fold-01-run-01.check\n",
      "62s - loss: 0.3193 - val_loss: 0.3697\n",
      "Epoch 9/50\n",
      "roc_auc: 0.85442 - roc_auc_val: 0.85422 - norm_gini: 0.70884 - norm_gini_val: 0.70844          \n",
      "Epoch 00008: norm_gini_val improved from 0.70548 to 0.70844, saving model to keras-5fold-run-01-v1-fold-01-run-01.check\n",
      "62s - loss: 0.3185 - val_loss: 0.3774\n",
      "Epoch 10/50\n",
      "roc_auc: 0.85606 - roc_auc_val: 0.85517 - norm_gini: 0.71212 - norm_gini_val: 0.71034          \n",
      "Epoch 00009: norm_gini_val improved from 0.70844 to 0.71034, saving model to keras-5fold-run-01-v1-fold-01-run-01.check\n",
      "62s - loss: 0.3178 - val_loss: 0.3645\n",
      "Epoch 11/50\n",
      "roc_auc: 0.85449 - roc_auc_val: 0.85417 - norm_gini: 0.70898 - norm_gini_val: 0.70833          \n",
      "Epoch 00010: norm_gini_val did not improve\n",
      "62s - loss: 0.3171 - val_loss: 0.3737\n",
      "Epoch 12/50\n",
      "roc_auc: 0.85267 - roc_auc_val: 0.85154 - norm_gini: 0.70534 - norm_gini_val: 0.70309          \n",
      "Epoch 00011: norm_gini_val did not improve\n",
      "62s - loss: 0.3164 - val_loss: 0.3797\n",
      "Epoch 13/50\n",
      "roc_auc: 0.8557 - roc_auc_val: 0.8549 - norm_gini: 0.71141 - norm_gini_val: 0.70981          \n",
      "Epoch 00012: norm_gini_val did not improve\n",
      "62s - loss: 0.3159 - val_loss: 0.3670\n",
      "Epoch 14/50\n",
      "roc_auc: 0.85529 - roc_auc_val: 0.85343 - norm_gini: 0.71057 - norm_gini_val: 0.70686          \n",
      "Epoch 00013: norm_gini_val did not improve\n",
      "62s - loss: 0.3155 - val_loss: 0.3699\n",
      "Epoch 15/50\n",
      "roc_auc: 0.85449 - roc_auc_val: 0.85342 - norm_gini: 0.70897 - norm_gini_val: 0.70683          \n",
      "Epoch 00014: norm_gini_val did not improve\n",
      "62s - loss: 0.3148 - val_loss: 0.3828\n",
      "Epoch 16/50\n",
      "roc_auc: 0.85566 - roc_auc_val: 0.85453 - norm_gini: 0.71133 - norm_gini_val: 0.70906          \n",
      "Epoch 00015: norm_gini_val did not improve\n",
      "60s - loss: 0.3144 - val_loss: 0.3664\n",
      "Epoch 17/50\n",
      "roc_auc: 0.85636 - roc_auc_val: 0.85515 - norm_gini: 0.71273 - norm_gini_val: 0.7103          \n",
      "Epoch 00016: norm_gini_val did not improve\n",
      "55s - loss: 0.3141 - val_loss: 0.3639\n",
      "Epoch 18/50\n",
      "roc_auc: 0.85859 - roc_auc_val: 0.85742 - norm_gini: 0.71717 - norm_gini_val: 0.71484          \n",
      "Epoch 00017: norm_gini_val improved from 0.71034 to 0.71484, saving model to keras-5fold-run-01-v1-fold-01-run-01.check\n",
      "59s - loss: 0.3141 - val_loss: 0.3686\n",
      "Epoch 19/50\n",
      "roc_auc: 0.85692 - roc_auc_val: 0.85634 - norm_gini: 0.71385 - norm_gini_val: 0.71267          \n",
      "Epoch 00018: norm_gini_val did not improve\n",
      "59s - loss: 0.3138 - val_loss: 0.3737\n",
      "Epoch 20/50\n",
      "roc_auc: 0.85723 - roc_auc_val: 0.85551 - norm_gini: 0.71446 - norm_gini_val: 0.71102          \n",
      "Epoch 00019: norm_gini_val did not improve\n",
      "59s - loss: 0.3135 - val_loss: 0.3532\n",
      "Epoch 21/50\n",
      "roc_auc: 0.85776 - roc_auc_val: 0.85481 - norm_gini: 0.71552 - norm_gini_val: 0.70961          \n",
      "Epoch 00020: norm_gini_val did not improve\n",
      "60s - loss: 0.3126 - val_loss: 0.3676\n",
      "Epoch 22/50\n",
      "roc_auc: 0.85808 - roc_auc_val: 0.85577 - norm_gini: 0.71615 - norm_gini_val: 0.71155          \n",
      "Epoch 00021: norm_gini_val did not improve\n",
      "55s - loss: 0.3131 - val_loss: 0.3564\n",
      "Epoch 23/50\n",
      "roc_auc: 0.85863 - roc_auc_val: 0.85586 - norm_gini: 0.71726 - norm_gini_val: 0.71172          \n",
      "Epoch 00022: norm_gini_val did not improve\n",
      "57s - loss: 0.3126 - val_loss: 0.3630\n",
      "Epoch 24/50\n",
      "roc_auc: 0.85901 - roc_auc_val: 0.85614 - norm_gini: 0.71802 - norm_gini_val: 0.71227          \n",
      "Epoch 00023: norm_gini_val did not improve\n",
      "55s - loss: 0.3126 - val_loss: 0.3732\n",
      "Epoch 25/50\n",
      "roc_auc: 0.86018 - roc_auc_val: 0.85808 - norm_gini: 0.72036 - norm_gini_val: 0.71615          \n",
      "Epoch 00024: norm_gini_val improved from 0.71484 to 0.71615, saving model to keras-5fold-run-01-v1-fold-01-run-01.check\n",
      "56s - loss: 0.3122 - val_loss: 0.3517\n",
      "Epoch 26/50\n",
      "roc_auc: 0.85973 - roc_auc_val: 0.85691 - norm_gini: 0.71945 - norm_gini_val: 0.71382          \n",
      "Epoch 00025: norm_gini_val did not improve\n",
      "55s - loss: 0.3116 - val_loss: 0.3681\n",
      "Epoch 27/50\n",
      "roc_auc: 0.85977 - roc_auc_val: 0.856 - norm_gini: 0.71953 - norm_gini_val: 0.712          \n",
      "Epoch 00026: norm_gini_val did not improve\n",
      "55s - loss: 0.3115 - val_loss: 0.3443\n",
      "Epoch 28/50\n",
      "roc_auc: 0.85648 - roc_auc_val: 0.8531 - norm_gini: 0.71296 - norm_gini_val: 0.7062          \n",
      "Epoch 00027: norm_gini_val did not improve\n",
      "54s - loss: 0.3114 - val_loss: 0.3700\n",
      "Epoch 29/50\n",
      "roc_auc: 0.86193 - roc_auc_val: 0.85846 - norm_gini: 0.72387 - norm_gini_val: 0.71691          \n",
      "Epoch 00028: norm_gini_val improved from 0.71615 to 0.71691, saving model to keras-5fold-run-01-v1-fold-01-run-01.check\n",
      "55s - loss: 0.3110 - val_loss: 0.3291\n",
      "Epoch 30/50\n",
      "roc_auc: 0.85941 - roc_auc_val: 0.85549 - norm_gini: 0.71883 - norm_gini_val: 0.71098          \n",
      "Epoch 00029: norm_gini_val did not improve\n",
      "56s - loss: 0.3107 - val_loss: 0.3464\n",
      "Epoch 31/50\n",
      "roc_auc: 0.85975 - roc_auc_val: 0.85651 - norm_gini: 0.71951 - norm_gini_val: 0.71301          \n",
      "Epoch 00030: norm_gini_val did not improve\n",
      "56s - loss: 0.3107 - val_loss: 0.3369\n",
      "Epoch 32/50\n",
      "roc_auc: 0.85985 - roc_auc_val: 0.85711 - norm_gini: 0.71971 - norm_gini_val: 0.71423          \n",
      "Epoch 00031: norm_gini_val did not improve\n",
      "58s - loss: 0.3106 - val_loss: 0.3453\n",
      "Epoch 33/50\n",
      "roc_auc: 0.8607 - roc_auc_val: 0.85687 - norm_gini: 0.7214 - norm_gini_val: 0.71374          \n",
      "Epoch 00032: norm_gini_val did not improve\n",
      "63s - loss: 0.3107 - val_loss: 0.3355\n",
      "Epoch 34/50\n",
      "roc_auc: 0.85971 - roc_auc_val: 0.85546 - norm_gini: 0.71941 - norm_gini_val: 0.71091          \n",
      "Epoch 00033: norm_gini_val did not improve\n",
      "81s - loss: 0.3104 - val_loss: 0.3728\n",
      "Epoch 35/50\n",
      "roc_auc: 0.86175 - roc_auc_val: 0.85769 - norm_gini: 0.7235 - norm_gini_val: 0.71538          \n",
      "Epoch 00034: norm_gini_val did not improve\n",
      "80s - loss: 0.3100 - val_loss: 0.3280\n",
      "Epoch 36/50\n",
      "roc_auc: 0.86135 - roc_auc_val: 0.85648 - norm_gini: 0.72269 - norm_gini_val: 0.71296          \n",
      "Epoch 00035: norm_gini_val did not improve\n",
      "83s - loss: 0.3096 - val_loss: 0.3396\n",
      "Epoch 37/50\n",
      "roc_auc: 0.85954 - roc_auc_val: 0.85472 - norm_gini: 0.71908 - norm_gini_val: 0.70945          \n",
      "Epoch 00036: norm_gini_val did not improve\n",
      "81s - loss: 0.3095 - val_loss: 0.3491\n",
      "Epoch 38/50\n",
      "roc_auc: 0.86338 - roc_auc_val: 0.8573 - norm_gini: 0.72677 - norm_gini_val: 0.7146          \n",
      "Epoch 00037: norm_gini_val did not improve\n",
      "81s - loss: 0.3095 - val_loss: 0.3480\n",
      "Epoch 39/50\n",
      "roc_auc: 0.8616 - roc_auc_val: 0.85602 - norm_gini: 0.72321 - norm_gini_val: 0.71205          \n",
      "Epoch 00038: norm_gini_val did not improve\n",
      "80s - loss: 0.3092 - val_loss: 0.3391\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "roc_auc: 0.86018 - roc_auc_val: 0.85528 - norm_gini: 0.72036 - norm_gini_val: 0.71055          \n",
      "Epoch 00039: norm_gini_val did not improve\n",
      "79s - loss: 0.3087 - val_loss: 0.3708\n",
      "Epoch 00039: early stopping\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Optimizer weight shape (20,) not compatible with provided weight shape (100,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5c75b4bf4831>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mnnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mnnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'keras-5fold-run-01-v1-fold-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%02d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-run-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%02d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.check'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0mscores_val_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mLL_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_val_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0moptimizer_weight_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_weights_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0moptimizer_weight_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moptimizer_weights_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_weight_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_weight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m     77\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                                  \u001b[0;34m' not compatible with '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                                  'provided weight shape ' + str(w.shape))\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Optimizer weight shape (20,) not compatible with provided weight shape (100,)"
     ]
    }
   ],
   "source": [
    "patience = 10\n",
    "batchsize = 128\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, random_state=5)\n",
    "starttime = timer(None)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(train, target)):\n",
    "    start_time = timer(None)\n",
    "    X_train, X_val = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_val = target[train_index], target[test_index]\n",
    "    train_ids, val_ids = tr_ids[train_index], tr_ids[test_index]\n",
    "    \n",
    "    #Compile\n",
    "    def baseline_model():\n",
    "        #Define our model\n",
    "        input_userf = Input(shape= (15,), name='user_feats')\n",
    "        em_userf = Dense(100, activation='relu')(input_userf)\n",
    "        \n",
    "        input_invest = Input(shape= (14,), name='invest_feats')\n",
    "        em_invest = Dense(10, activation='relu')(input_invest)\n",
    "        \n",
    "        input_acc = Input(shape= (38,), name='acc_feats')\n",
    "        em_acc = Dense(6, activation='relu')(input_acc)\n",
    "\n",
    "        input_misc = Input(shape= (20,), name='misc_feats')\n",
    "        em_misc = Dense(3, activation='relu')(input_misc)\n",
    "    \n",
    "        input_pct = Input(shape= (4,), name='percent_feats')\n",
    "        em_pct = Dense(3, activation='relu')(input_pct)\n",
    "\n",
    "        input_bal = Input(shape= (8,), name='balace_feats')\n",
    "        em_bal = Dense(4, activation='relu')(input_bal)\n",
    "        \n",
    "        input_ind02 = Input(shape= (12,), name='C_prev')\n",
    "        em_ind02 = Dense(20, activation='relu')(input_ind02)\n",
    "        #em_ind02 = Reshape(target_shape=(3,))(em_ind02)\n",
    "\n",
    "        input_ind04 = Input(shape= (12,), name='D_prev')\n",
    "        em_ind04 = Dense(20, activation='relu')(input_ind04)\n",
    "        #em_ind04 = Reshape(target_shape=(3,))(em_ind04)\n",
    "\n",
    "        input_ind05 = Input(shape= (24,), name='All_channel_credit')\n",
    "        em_ind05 = Dense(20, activation='relu')(input_ind05)\n",
    "        #em_ind05 = Reshape(target_shape=(10,))(em_ind05)\n",
    "\n",
    "        input_car01 = Input(shape= (54,), name='All_channel_debit')\n",
    "        em_car01 = Dense(20, activation='relu')(input_car01)\n",
    "        #em_car01 = Reshape(target_shape=(10,))(em_car01)\n",
    "\n",
    "\n",
    "        input_car04 = Input(shape= (12,), name='custinit_credit')\n",
    "        em_car04 = Dense(3, activation='relu')(input_car04)\n",
    "        #em_car04 = Reshape(target_shape=(3,))(em_car04)\n",
    "\n",
    "        input_car05 = Input(shape= (12,), name='custinit_debit')\n",
    "        em_car05 = Dense(3, activation='relu')(input_car05)\n",
    "        #em_car05 = Reshape(target_shape=(3,))(em_car05)\n",
    "\n",
    "        input_car06 = Input(shape= (24,), name='cashwithdraw')\n",
    "        em_car06 = Dense(6, activation='relu')(input_car06)\n",
    "        #em_car06 = Reshape(target_shape=(6,))(em_car06)\n",
    "\n",
    "        input_car07 = Input(shape= (12,), name='cashdeposit')\n",
    "        em_car07 = Dense(4, activation='relu')(input_car07)\n",
    "        #em_car07 = Reshape(target_shape=(4,))(em_car07)\n",
    "\n",
    "        input_car08 = Input(shape= (6,), name='cnr')\n",
    "        em_car08 = Dense(20, activation='relu')(input_car08)\n",
    "        #em_car08 = Reshape(target_shape=(3,))(em_car08)\n",
    "\n",
    "        input_car09 = Input(shape= (6,), name='bal')\n",
    "        em_car09 = Dense(20, activation='relu')(input_car09)\n",
    "        #em_car09 = Reshape(target_shape=(3,))(em_car09)\n",
    "\n",
    "        input_car10 = Input(shape= (6,), name='eop')\n",
    "        em_car10 = Dense(20, activation='relu')(input_car10)\n",
    "        #em_car10 = Reshape(target_shape=(3,))(em_car10)\n",
    "\n",
    "        input_car11 = Input(shape= (11,), name='cr_amb')\n",
    "        em_car11 = Dense(10, activation='relu')(input_car11)\n",
    "        #em_car11 = Reshape(target_shape=(3,))(em_car11)\n",
    "\n",
    "        input_car12 = Input(shape= (6,), name='atm_amt')\n",
    "        em_car12 = Dense(3, activation='relu')(input_car12)\n",
    "        \n",
    "        newfeats = Input(shape=(37,), name='new_feats')\n",
    "\n",
    "        x = concatenate([em_userf, em_acc, em_invest, em_misc, em_pct, em_bal, newfeats, em_ind02,\n",
    "                         em_ind04, em_ind05, em_car01, em_car04, em_car05,\n",
    "                        em_car06, em_car07, em_car08, em_car09, em_car10, em_car11, em_car12\n",
    "                    ])\n",
    "\n",
    "\n",
    "\n",
    "        #x = BatchNormalization()(x)\n",
    "        #x = Dropout(rate=0.01)(x)\n",
    "        #x = Dense(300, activation='relu', kernel_regularizer=regularizers.l2(0.00001))(x)\n",
    "        x = Dense(300, activation='relu', kernel_initializer=\"glorot_normal\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(rate=0.5)(x)\n",
    "        \n",
    "        \n",
    "        #x = BatchNormalization()(x)\n",
    "        #x = Dropout(rate=0.01)(x)\n",
    "        #x = Dense(150, activation='relu', kernel_regularizer=regularizers.l2(0.0))(x)\n",
    "        x = Dense(100, activation='relu', kernel_initializer=\"glorot_normal\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(rate=0.25)(x)\n",
    "        \n",
    "\n",
    "        #x = BatchNormalization()(x)\n",
    "        #x = Dropout(rate=0.01)(x)\n",
    "        #x = Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.00))(x)\n",
    "        #x4 = Dense(5, activation='relu')(x)\n",
    "        \n",
    "        x = Dense(50, activation='relu', kernel_initializer=\"glorot_normal\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(rate=0.15)(x)\n",
    "        \n",
    "        x = Dense(25, activation='relu', kernel_initializer=\"glorot_normal\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(rate=0.1)(x)\n",
    "        \n",
    "\n",
    "        main_output = Dense(1, activation='sigmoid', name='main_output')(x)\n",
    "        \n",
    "        model = Model(inputs=[input_userf, input_acc, input_invest, input_misc, input_pct, input_bal,\n",
    "                      newfeats,  input_ind02, input_ind04, input_ind05, input_car01, input_car04,\n",
    "                      input_car05, input_car06, input_car07, input_car08, input_car09, input_car10,\n",
    "                      input_car11, input_car12], \n",
    "              outputs=main_output)\n",
    "        \n",
    "        adam = keras.optimizers.Adam(lr = 0.001, decay=1e-7)\n",
    "        model.compile(optimizer=adam, loss='binary_crossentropy', metrics = [])\n",
    "        \n",
    "        return model\n",
    "\n",
    "\n",
    "# This is where we repeat the runs for each fold. If you choose runs=1 above, it will run a \n",
    "# regular N-fold procedure.\n",
    "\n",
    "#########\n",
    "# It is important to leave the call to random seed here, so each run starts with a different seed.\n",
    "#########\n",
    "\n",
    "    for run in range(runs):\n",
    "        print('\\n Fold %d - Run %d\\n' % ((i + 1), (run + 1)))\n",
    "        np.random.seed()\n",
    "        \n",
    "        callbacks = [\n",
    "        roc_auc_callback(training_data=(X_train, y_train),validation_data=(X_val, y_val)),  # call this before EarlyStopping\n",
    "        EarlyStopping(monitor='norm_gini_val', patience=patience, mode='max', verbose=1),\n",
    "        CSVLogger('keras-5fold-run-01-v1-epochs.log', separator=',', append=False),\n",
    "        ModelCheckpoint(\n",
    "                'keras-5fold-run-01-v1-fold-' + str('%02d' % (i + 1)) + '-run-' + str('%02d' % (run + 1)) + '.check',\n",
    "                monitor='norm_gini_val', mode='max', # mode must be set to max or Keras will be confused\n",
    "                save_best_only=True,\n",
    "                verbose=1)\n",
    "        ]\n",
    "\n",
    "# The classifier is defined here. Epochs should be be set to a very large number (not 3 like below) which \n",
    "# will never be reached anyway because of early stopping. I usually put 5000 there. Because why not.\n",
    "\n",
    "        nnet = KerasClassifier(\n",
    "            build_fn=baseline_model,\n",
    "# Epoch needs to be set to a very large number ; early stopping will prevent it from reaching\n",
    "#            epochs=5000,\n",
    "            epochs=50,\n",
    "            batch_size=batchsize,\n",
    "            validation_data=(split_features(X_val), y_val),\n",
    "            verbose=2,\n",
    "            shuffle=True,\n",
    "        callbacks = callbacks)\n",
    "        \n",
    "        fit = nnet.fit(split_features(X_train), y_train)\n",
    "        \n",
    "# We want the best saved model - not the last one where the training stopped. So we delete the old \n",
    "# model instance and load the model from the last saved checkpoint. Next we predict values both for \n",
    "# validation and test data, and create a summary of parameters for each run.\n",
    "\n",
    "        del nnet\n",
    "        nnet = load_model('keras-5fold-run-01-v1-fold-' + str('%02d' % (i + 1)) + '-run-' + str('%02d' % (run + 1)) + '.check')\n",
    "        scores_val_run = nnet.predict(split_features(X_val), verbose=0)\n",
    "        LL_run = log_loss(y_val, scores_val_run)\n",
    "        print('\\n Fold %d Run %d Log-loss: %.5f' % ((i + 1), (run + 1), LL_run))\n",
    "        AUC_run = roc_auc_score(y_val, scores_val_run)\n",
    "        print(' Fold %d Run %d AUC: %.5f' % ((i + 1), (run + 1), AUC_run))\n",
    "        print(' Fold %d Run %d normalized gini: %.5f' % ((i + 1), (run + 1), AUC_run*2-1))\n",
    "        y_pred_run = nnet.predict(split_features(test), verbose=0)\n",
    "        if run > 0:\n",
    "            scores_val = scores_val + scores_val_run\n",
    "            y_pred = y_pred + y_pred_run\n",
    "        else:\n",
    "            scores_val = scores_val_run\n",
    "            y_pred = y_pred_run\n",
    "            \n",
    "# We average all runs from the same fold and provide a parameter summary for each fold. Unless something \n",
    "# is wrong, the numbers printed here should be better than any of the individual runs.\n",
    "\n",
    "    scores_val = scores_val / runs\n",
    "    y_pred = y_pred / runs\n",
    "    LL = log_loss(y_val, scores_val)\n",
    "    print('\\n Fold %d Log-loss: %.5f' % ((i + 1), LL))\n",
    "    AUC = roc_auc_score(y_val, scores_val)\n",
    "    print(' Fold %d AUC: %.5f' % ((i + 1), AUC))\n",
    "    print(' Fold %d normalized gini: %.5f' % ((i + 1), AUC*2-1))\n",
    "    timer(start_time)\n",
    "    \n",
    "# We add up predictions on the test data for each fold. Create out-of-fold predictions for validation data.\n",
    "\n",
    "    if i > 0:\n",
    "        fpred = pred + y_pred\n",
    "        avreal = np.concatenate((avreal, y_val), axis=0)\n",
    "        avpred = np.concatenate((avpred, scores_val), axis=0)\n",
    "        avids = np.concatenate((avids, val_ids), axis=0)\n",
    "    else:\n",
    "        fpred = y_pred\n",
    "        avreal = y_val\n",
    "        avpred = scores_val\n",
    "        avids = val_ids\n",
    "    pred = fpred\n",
    "    cv_LL = cv_LL + LLUCID_ID\n",
    "    cv_AUC = cv_AUC + AUC\n",
    "    cv_gini = cv_gini + (AUC*2-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LL_oof = log_loss(avreal, avpred)\n",
    "print('\\n Average Log-loss: %.5f' % (cv_LL/folds))\n",
    "print(' Out-of-fold Log-loss: %.5f' % LL_oof)\n",
    "AUC_oof = roc_auc_score(avreal, avpred)\n",
    "print('\\n Average AUC: %.5f' % (cv_AUC/folds))\n",
    "print(' Out-of-fold AUC: %.5f' % AUC_oof)\n",
    "print('\\n Average normalized gini: %.5f' % (cv_gini/folds))\n",
    "print(' Out-of-fold normalized gini: %.5f' % (AUC_oof*2-1))\n",
    "score = str(round((AUC_oof*2-1), 5))\n",
    "timer(starttime)\n",
    "mpred = pred / folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_proba_corr2(preds):\n",
    "    d0 = 0.5\n",
    "    d1 = 1 - d0\n",
    "    r0 = np.mean(preds)\n",
    "    r1 = 1 - r0\n",
    "    gamma_0 = r0/d0\n",
    "    gamma_1 = r1/d1\n",
    "    return gamma_1*preds/(gamma_1*preds + gamma_0*(1 - preds))\n",
    "\n",
    "avpred_corr = predict_proba_corr2(avpred[:,0])\n",
    "mpred_corr = predict_proba_corr2(mpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_top(y, preds):\n",
    "    y = np.array(y)\n",
    "    n = int(len(preds) * 0.2)\n",
    "    if np.ndim(preds) == 1:\n",
    "        indices = np.argsort(preds)[::-1][:n]\n",
    "    else:\n",
    "        indices = np.argsort(preds[:, 1])[::-1][:n]\n",
    "    return sum(y[indices])/sum(y)\n",
    "\n",
    "eval_top(avreal, avpred_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('#\\n Writing results')\n",
    "now = datetime.now()\n",
    "#oof_result = pd.DataFrame(avreal, columns=['Responders'])\n",
    "oof_result['Responders'] = avpred_corr\n",
    "oof_result['UCIC_ID'] = avids\n",
    "oof_result.sort_values('UCIC_ID', ascending=True, inplace=True)\n",
    "oof_result = oof_result.set_index('UCID_ID')\n",
    "sub_file = 'train_10fold-keras-run-05-v1-oof_' + str(score) + '_' + str(now.strftime('%Y-%m-%d-%H-%M')) + '.csv'\n",
    "print('\\n Writing out-of-fold file:  %s' % sub_file)\n",
    "oof_result.to_csv(sub_file, index=True, index_label='UCIC_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(mpred_corr, columns=['Responders'])\n",
    "result['UCIC_ID'] = te_ids\n",
    "result = result.set_index('UCIC_ID')\n",
    "print('\\n First 10 lines of your 5-fold average prediction:\\n')\n",
    "print(result.head(10))\n",
    "sub_file = 'submission_10fold-average-keras-run-05-v1_' + str(score) + '_' + str(now.strftime('%Y-%m-%d-%H-%M')) + '.csv'\n",
    "print('\\n Writing submission:  %s' % sub_file)\n",
    "result.to_csv(sub_file, index=True, index_label='UCIC_ID')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.distplot(result[\"Responders\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
