{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import category_encoders as en\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, make_union\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, StratifiedKFold\n",
    "\n",
    "#from OneHotEncoderDf import OneHotEncoderDf\n",
    "#from LabelEncoderDf import LabelEncoderDf\n",
    "#from FeatureSubsetTransformer import FeatureSubsetTransformer\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from skopt import BayesSearchCV, gp_minimize, forest_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt import dump\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "\n",
    "#import xgboost as xgb\n",
    "\n",
    "#import category_encoders as en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_proba_corr(self, X):\n",
    "    preds = self.predict_proba(X)[:,1]\n",
    "    d0 = 0.5\n",
    "    d1 = 1 - d0\n",
    "    r0 = np.mean(preds)\n",
    "    r1 = 1 - r0\n",
    "    gamma_0 = r0/d0\n",
    "    gamma_1 = r1/d1\n",
    "    return gamma_1*preds/(gamma_1*preds + gamma_0*(1 - preds))\n",
    "\n",
    "def eval_top(y, preds):\n",
    "    y = y.values\n",
    "    n = int(len(preds) * 0.2)\n",
    "    indices = np.argsort(preds)[::-1][:n]\n",
    "    #print(len(indices))\n",
    "    return sum(y[indices])/sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../input/train.csv\", low_memory=False)\n",
    "test = pd.read_csv(\"../../input/test.csv\", low_memory=False)\n",
    "#data_df = train.append(test)\n",
    "# base_feats = [f for f in data_df.columns if f not in [\"UCIC_ID\", \"Responders\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_cols = list(train.select_dtypes(['object']).columns.values)\n",
    "for col in cat_cols:\n",
    "    lb = LabelEncoder()\n",
    "    lb.fit(pd.concat([train[col], test[col]]).astype(str).fillna('-1'))\n",
    "    train[col] = lb.transform(train[col].astype(str).fillna('-1'))\n",
    "    test[col] = lb.transform(test[col].astype(str).fillna('-1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_feats = [f for f in train.columns if f not in ['UCIC_ID','Responders'] + list(cat_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[num_feats] = train[num_feats].fillna(0)\n",
    "test[num_feats] = test[num_feats].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train = data_df.iloc[:train.shape[0]]\n",
    "#test = data_df.iloc[train.shape[0]:]\n",
    "X = train[num_feats + cat_cols]\n",
    "y = train['Responders']\n",
    "X_test = test[num_feats + cat_cols]\n",
    "\n",
    "cvlist = list(StratifiedKFold(n_splits=5, random_state=5).split(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets encode all categoricals with likelihood\n",
    "#Writing cv method completely in pandas\n",
    "def cv_feat_pd1col(data_df, eval_col, target_col, cvlist, func, thresh=3):\n",
    "    cv_vals = np.ones(len(data_df)) * np.nan #Initialize\n",
    "    for tr_index, val_index in cvlist:\n",
    "        tr_func_dict = data_df.loc[tr_index].groupby(eval_col)[target_col].apply(lambda x: \n",
    "                                                    func(x) if len(x) >= thresh  else np.nan).to_dict()\n",
    "        #print(tr_func_dict)\n",
    "        cv_vals[val_index] = data_df.loc[val_index, eval_col].apply(lambda row: tr_func_dict[row]\n",
    "                                                                     if row in tr_func_dict\n",
    "                                                                     else func(data_df.loc[tr_index, target_col]))\n",
    "    return cv_vals\n",
    "\n",
    "def cv_feat_pdcols(data_df, eval_cols, target_col, cvlist, func, thresh=3):\n",
    "    cv_vals = np.ones(len(data_df)) * np.nan #Initialize\n",
    "    X = data_df.copy()\n",
    "    X['eval_records'] = data_df[eval_cols].to_records(index=False)\n",
    "    return cv_feat_pd1col(X, 'eval_records', target_col, cvlist, func, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  HNW_CATEGORY\n",
      "Processing  OCCUP_ALL_NEW\n",
      "Processing  city\n",
      "Processing  FINAL_WORTH_prev1\n",
      "Processing  EFT_SELF_TRANSFER_PrevQ1\n",
      "Processing  Charges_cnt_PrevQ1_N\n",
      "Processing  gender_bin\n",
      "Processing  RBI_Class_Audit\n",
      "Processing  zip\n",
      "Processing  brn_code\n",
      "Processing  age\n"
     ]
    }
   ],
   "source": [
    "#Get likehood features\n",
    "ltrain = len(train)\n",
    "ltest  = len(test)\n",
    "test['Responders'] = np.nan\n",
    "all_data = pd.concat([train, test]).reset_index(drop=True)\n",
    "cvtraintest = [[np.arange(ltrain), np.arange(ltrain, ltrain + ltest)]]\n",
    "\n",
    "\n",
    "for col in ['HNW_CATEGORY', 'OCCUP_ALL_NEW', 'city', 'FINAL_WORTH_prev1', 'EFT_SELF_TRANSFER_PrevQ1',\n",
    "           'Charges_cnt_PrevQ1_N', 'gender_bin', 'RBI_Class_Audit', 'zip', 'brn_code', 'age']:\n",
    "    print(\"Processing \", col)\n",
    "    train[col+'_likelihood'] = cv_feat_pd1col(train, col, 'Responders', cvlist, np.mean, 50)\n",
    "    test[col+'_likelihood'] = cv_feat_pd1col(all_data, col, 'Responders', cvtraintest, np.mean, 50)[ltrain:]\n",
    "    \n",
    "del all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"EOP_prev1_cat\"] = pd.qcut(train[\"EOP_prev1\"], q = 50, labels = False, duplicates = \"drop\")\n",
    "test[\"EOP_prev1_cat\"] = pd.qcut(test[\"EOP_prev1\"], q = 50, labels = False, duplicates = \"drop\")\n",
    "\n",
    "train[\"age_cat\"] = [1 if x <= 18 else 0 for x in train[\"age\"]]\n",
    "test[\"age_cat\"] = [1 if x <= 18 else 0 for x in test[\"age\"]]\n",
    "\n",
    "cat_cols.append(\"EOP_prev1_cat\")\n",
    "cat_cols.append(\"age_cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Mean of of drops; std in drops\n",
    "train.loc[:,'EOP_mean_drop'] = train[['EOP_prev1', \"EOP_prev2\", 'EOP_prev3',\n",
    "                               'EOP_prev4', \"EOP_prev5\", 'EOP_prev6',]].apply(\n",
    "                                                            lambda r: np.mean(r), axis=1)\n",
    "train.loc[:,'EOP_std_drop'] = train[['EOP_prev1', \"EOP_prev2\", 'EOP_prev3',\n",
    "                               'EOP_prev4', \"EOP_prev5\", 'EOP_prev6',]].apply(\n",
    "                                                            lambda r: np.std(r), axis=1)\n",
    "\n",
    "test.loc[:,'EOP_mean_drop'] = test[['EOP_prev1', \"EOP_prev2\", 'EOP_prev3',\n",
    "                               'EOP_prev4', \"EOP_prev5\", 'EOP_prev6',]].apply(\n",
    "                                                            lambda r: np.mean(r), axis=1)\n",
    "test.loc[:,'EOP_std_drop'] = test[['EOP_prev1', \"EOP_prev2\", 'EOP_prev3',\n",
    "                               'EOP_prev4', \"EOP_prev5\", 'EOP_prev6',]].apply(\n",
    "                                                            lambda r: np.std(r), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Mean of of drops; std in drops\n",
    "train.loc[:,'CR_mean_drop'] = train[['CR_AMB_Drop_Build_1', 'CR_AMB_Drop_Build_2', \n",
    "                               'CR_AMB_Drop_Build_3', 'CR_AMB_Drop_Build_4',\n",
    "                              'CR_AMB_Drop_Build_5']].apply(lambda r: np.mean(r), axis=1)\n",
    "train.loc[:,'CR_std_drop'] = train[['CR_AMB_Drop_Build_1', 'CR_AMB_Drop_Build_2', \n",
    "                               'CR_AMB_Drop_Build_3', 'CR_AMB_Drop_Build_4',\n",
    "                              'CR_AMB_Drop_Build_5']].apply(lambda r: np.std(r), axis=1)\n",
    "\n",
    "test.loc[:,'CR_mean_drop'] = test[['CR_AMB_Drop_Build_1', 'CR_AMB_Drop_Build_2', \n",
    "                               'CR_AMB_Drop_Build_3', 'CR_AMB_Drop_Build_4',\n",
    "                              'CR_AMB_Drop_Build_5']].apply(lambda r: np.mean(r), axis=1)\n",
    "test.loc[:,'CR_std_drop'] = test[['CR_AMB_Drop_Build_1', 'CR_AMB_Drop_Build_2', \n",
    "                               'CR_AMB_Drop_Build_3', 'CR_AMB_Drop_Build_4',\n",
    "                              'CR_AMB_Drop_Build_5']].apply(lambda r: np.std(r), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sum of drops\n",
    "train.loc[:,'CR_sum_drop'] = train[['CR_AMB_Drop_Build_1', 'CR_AMB_Drop_Build_2', \n",
    "                               'CR_AMB_Drop_Build_3', 'CR_AMB_Drop_Build_4',\n",
    "                              'CR_AMB_Drop_Build_5']].apply(lambda r: np.sum(r), axis=1)\n",
    "\n",
    "test.loc[:,'CR_sum_drop'] = test[['CR_AMB_Drop_Build_1', 'CR_AMB_Drop_Build_2', \n",
    "                               'CR_AMB_Drop_Build_3', 'CR_AMB_Drop_Build_4',\n",
    "                              'CR_AMB_Drop_Build_5']].apply(lambda r: np.sum(r), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ratio average balance to EOB and CR of last month\n",
    "train.loc[:,'EOB_rat1'] = train['EOP_prev1']/(1 + train['I_AQB_PrevQ1'])\n",
    "train.loc[:,'CR_rat1'] = train['CR_AMB_Drop_Build_1']/(1 + train['I_AQB_PrevQ1'])\n",
    "\n",
    "test.loc[:,'EOB_rat1'] = test['EOP_prev1']/(1 + test['I_AQB_PrevQ1'])\n",
    "test.loc[:,'CR_rat1'] = test['CR_AMB_Drop_Build_1']/(1 + test['I_AQB_PrevQ1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.loc[:,'EOB_rat2'] = train['EOP_prev1']/(1 + train['I_AQB_PrevQ2'].clip(0, 10**9))\n",
    "train.loc[:,'CR_rat2'] = train['CR_AMB_Drop_Build_1']/(1 + train['I_AQB_PrevQ2'].clip(0, 10**9))\n",
    "\n",
    "test.loc[:,'EOB_rat2'] = test['EOP_prev1']/(1 + test['I_AQB_PrevQ2'].clip(0, 10**9))\n",
    "test.loc[:,'CR_rat2'] = test['CR_AMB_Drop_Build_1']/(1 + test['I_AQB_PrevQ2'].clip(0, 10**9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ratio of balances\n",
    "train.loc[:,'bal_rats'] = train['I_AQB_PrevQ2']/(1 + train['I_AQB_PrevQ1'])\n",
    "test.loc[:,'bal_rats'] = test['I_AQB_PrevQ2']/(1 + test['I_AQB_PrevQ1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#log values\n",
    "train.loc[:,'EOP_prev1log'] = np.log1p(train['EOP_prev1'].clip(0, 10**9))\n",
    "test.loc[:,'EOP_prev1log'] = np.log1p(test['EOP_prev1'].clip(0, 10**9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Encode branch code and city by average balnces of their customers\n",
    "train.loc[:,'brn_bal'] = train.groupby('brn_code')['I_AQB_PrevQ1'].transform(np.mean)\n",
    "test.loc[:,'brn_bal'] = test.groupby('brn_code')['I_AQB_PrevQ1'].transform(np.mean)\n",
    "\n",
    "train.loc[:,'zip_bal'] = train.groupby('zip')['I_AQB_PrevQ1'].transform(np.mean)\n",
    "test.loc[:,'zip_bal'] = test.groupby('zip')['I_AQB_PrevQ1'].transform(np.mean)\n",
    "\n",
    "train.loc[:,'brn_churn'] = train.groupby('brn_code')['CR_rat1'].transform(np.mean)\n",
    "test.loc[:,'brn_churn'] = test.groupby('brn_code')['CR_rat1'].transform(np.mean)\n",
    "\n",
    "train.loc[:,'zip_churn'] = train.groupby('zip')['CR_rat1'].transform(np.mean)\n",
    "test.loc[:,'zip_churn'] = test.groupby('zip')['CR_rat1'].transform(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Decline features\n",
    "train.loc[:,'bal_decline6'] = (train['BAL_prev6'] - train['BAL_prev1'])/(1 + train['I_AQB_PrevQ2'].clip(0, 10**9))\n",
    "train.loc[:,'bal_decline5'] = (train['BAL_prev5'] - train['BAL_prev1'])/(1 + train['I_AQB_PrevQ2'].clip(0, 10**9))\n",
    "train.loc[:,'bal_decline4'] = (train['BAL_prev4'] - train['BAL_prev1'])/(1 + train['I_AQB_PrevQ2'].clip(0, 10**9))\n",
    "train.loc[:,'bal_decline3'] = (train['BAL_prev3'] - train['BAL_prev1'])/(1 + train['I_AQB_PrevQ2'].clip(0, 10**9))\n",
    "train.loc[:,'bal_decline2'] = (train['BAL_prev2'] - train['BAL_prev1'])/(1 + train['I_AQB_PrevQ2'].clip(0, 10**9))\n",
    "\n",
    "test.loc[:,'bal_decline6'] = (test['BAL_prev6'] - test['BAL_prev1'])/(1 + test['I_AQB_PrevQ2'].clip(0, 10**9))\n",
    "test.loc[:,'bal_decline5'] = (test['BAL_prev5'] - test['BAL_prev1'])/(1 + test['I_AQB_PrevQ2'].clip(0, 10**9))\n",
    "test.loc[:,'bal_decline4'] = (test['BAL_prev4'] - test['BAL_prev1'])/(1 + test['I_AQB_PrevQ2'].clip(0, 10**9))\n",
    "test.loc[:,'bal_decline3'] = (test['BAL_prev3'] - test['BAL_prev1'])/(1 + test['I_AQB_PrevQ2'].clip(0, 10**9))\n",
    "test.loc[:,'bal_decline2'] = (test['BAL_prev2'] - test['BAL_prev1'])/(1 + test['I_AQB_PrevQ2'].clip(0, 10**9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Mean, std and ratio of debits\n",
    "train.loc[:,'debits_mean'] = train[['D_prev1', 'D_prev2', 'D_prev3', 'D_prev4',\n",
    "                              'D_prev5', 'D_prev6']].apply(lambda r: np.mean(r), axis=1) \n",
    "train.loc[:,'debits_std'] = train[['D_prev1', 'D_prev2', 'D_prev3', 'D_prev4',\n",
    "                              'D_prev5', 'D_prev6']].apply(lambda r: np.std(r), axis=1)\n",
    "train.loc[:,'debit1_rat'] = train['D_prev1']/(1 + train['debits_mean'].clip(0, 10**8))\n",
    "\n",
    "test.loc[:,'debits_mean'] = test[['D_prev1', 'D_prev2', 'D_prev3', 'D_prev4',\n",
    "                              'D_prev5', 'D_prev6']].apply(lambda r: np.mean(r), axis=1) \n",
    "test.loc[:,'debits_std'] = test[['D_prev1', 'D_prev2', 'D_prev3', 'D_prev4',\n",
    "                             'D_prev5', 'D_prev6']].apply(lambda r: np.std(r), axis=1)\n",
    "test.loc[:,'debit1_rat'] = test['D_prev1']/(1 + test['debits_mean'].clip(0, 10**8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Likelihood of EOBprev1 ratio and EOBprev1 after splitting them into categories\n",
    "_, bins1 = pd.qcut(pd.concat([train['EOB_rat1'], test['EOB_rat1']]), \n",
    "                   50, duplicates='drop', retbins=True, labels=False)\n",
    "_, bins2 = pd.qcut(pd.concat([train['EOP_prev1'], test['EOP_prev1']]), x\n",
    "                   50, duplicates='drop', retbins=True, labels=False)\n",
    "\n",
    "train.loc[:,'EOB_rat1qcut'] = pd.cut(train['EOB_rat1'], bins=bins1, labels=False)\n",
    "train.loc[:,'EOB_prev1qcut'] = pd.cut(train['EOP_prev1'], bins=bins2, labels=False)\n",
    "\n",
    "test.loc[:,'EOB_rat1qcut'] = pd.cut(test['EOB_rat1'], bins=bins1, labels=False)\n",
    "test.loc[:,'EOB_prev1qcut'] = pd.cut(test['EOP_prev1'], bins=bins2, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "5\n",
      "17\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "#user acc features\n",
    "growth_preclose_feats = ['RD_PREM_CLOSED_PREVQ1' ,'FD_PREM_CLOSED_PREVQ1']\n",
    "\n",
    "#Premature loan closure\n",
    "loan_preclose_feats = [f for f in train.columns if ('_PREM_CLOSED' in f) & (f not in growth_preclose_feats)]\n",
    "\n",
    "#Closure of growth accounts in last quarter\n",
    "growth_close_feats = ['RD_CLOSED_PREVQ1', 'FD_CLOSED_PREVQ1']\n",
    "\n",
    "#CLosure of growth accounts in last year\n",
    "growth_close_feats2 = ['DEMAT_CLOSED_PREV1YR', 'SEC_ACC_CLOSED_PREV1YR']\n",
    "\n",
    "#Closure of loan accounts in last quarter\n",
    "loan_close_feats = train.filter(regex='(?<!PREM)(_Closed_PrevQ1|_CLOSED_PREVQ1)').columns.tolist() + ['CC_CLOSED_PREVQ1']\n",
    "print(len(loan_close_feats))\n",
    "\n",
    "#Live growth accounts\n",
    "growth_accounts_live = ['DEMAT_TAG_LIVE', 'SEC_ACC_TAG_LIVE', 'MF_TAG_LIVE', 'RD_TAG_LIVE', 'FD_TAG_LIVE']\n",
    "print(len(growth_accounts_live))\n",
    "\n",
    "#Live loan accounts\n",
    "loan_accounts_live = train.filter(regex='(_LIVE|live)').columns.tolist()\n",
    "loan_accounts_live = [f for f in loan_accounts_live if f not in growth_accounts_live]\n",
    "print(len(loan_accounts_live))\n",
    "\n",
    "#Loan flags\n",
    "loan_flags = train.filter(regex='_DATE$').columns\n",
    "print(len(loan_flags))\n",
    "\n",
    "train.loc[:,'acc_prem_close'] = train[loan_preclose_feats].fillna(0).apply(lambda row: np.any(row), axis=1)\n",
    "test.loc[:,'acc_prem_close'] = test[loan_preclose_feats].fillna(0).apply(lambda row: np.any(row), axis=1)\n",
    "\n",
    "train.loc[:,'acc_prem_close_sum'] = train[loan_preclose_feats].fillna(0).apply(lambda row: sum(row), axis=1).clip(0,2)\n",
    "test.loc[:,'acc_prem_close_sum'] = test[loan_preclose_feats].fillna(0).apply(lambda row: sum(row), axis=1).clip(0,2)\n",
    "\n",
    "train.loc[:,'loan_close_num'] = train[loan_close_feats].fillna(0).apply(lambda row: sum(row), axis=1).clip(0,3)\n",
    "test.loc[:,'loan_close_num'] = test[loan_close_feats].fillna(0).apply(lambda row: sum(row), axis=1).clip(0,3)\n",
    "\n",
    "train.loc[:,'growth_close_num'] = train[growth_close_feats].fillna(0).apply(lambda row: sum(row), axis=1)\n",
    "test.loc[:,'growth_close_num'] = test[growth_close_feats].fillna(0).apply(lambda row: sum(row), axis=1)\n",
    "\n",
    "train.loc[:,'loan_live'] = train[loan_accounts_live].replace('Y',1).fillna(0).apply(lambda row: sum(row), axis=1).clip(0, 3)\n",
    "test.loc[:,'loan_live'] = test[loan_accounts_live].replace('Y',1).fillna(0).apply(lambda row: sum(row), axis=1).clip(0, 3)\n",
    "\n",
    "train[loan_flags] = train[loan_flags].fillna(0)\n",
    "train.loc[:,'loan_flag_sum1'] = train[loan_flags].apply(lambda row: sum([r==1 for r in row]), \n",
    "                                                  axis=1)\n",
    "train.loc[:,'loan_flag_sum2'] = train[loan_flags].apply(lambda row: sum([r==2 for r in row]), \n",
    "                                                  axis=1)\n",
    "\n",
    "test[loan_flags] = test[loan_flags].fillna(0)\n",
    "test.loc[:,'loan_flag_sum1'] = test[loan_flags].apply(lambda row: sum([r==1 for r in row]), \n",
    "                                                  axis=1)\n",
    "test.loc[:,'loan_flag_sum2'] = test[loan_flags].apply(lambda row: sum([r==2 for r in row]), \n",
    "                                                  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Invest features\n",
    "train.loc[:,'FD_Q1_Q2_diffabs'] = (train['NO_OF_FD_BOOK_PrevQ1'] - train['NO_OF_FD_BOOK_PrevQ2']).clip(-7,7)\n",
    "train.loc[:,'NO_OF_FD_BOOK_PrevQ1'] = train['NO_OF_FD_BOOK_PrevQ1'].clip(0, 25)\n",
    "train.loc[:,'NO_OF_FD_BOOK_PrevQ2'] = train['NO_OF_FD_BOOK_PrevQ2'].clip(0, 25)\n",
    "\n",
    "test.loc[:,'FD_Q1_Q2_diffabs'] = (test['NO_OF_FD_BOOK_PrevQ1'] - test['NO_OF_FD_BOOK_PrevQ2']).clip(-7,7)\n",
    "test.loc[:,'NO_OF_FD_BOOK_PrevQ1'] = test['NO_OF_FD_BOOK_PrevQ1'].clip(0, 25)\n",
    "test.loc[:,'NO_OF_FD_BOOK_PrevQ2'] = test['NO_OF_FD_BOOK_PrevQ2'].clip(0, 25)\n",
    "\n",
    "train.loc[:,'NO_OF_RD_BOOK_PrevQ1'] = train['NO_OF_RD_BOOK_PrevQ1'].clip(0, 20)\n",
    "train.loc[:,'NO_OF_RD_BOOK_PrevQ2'] = train['NO_OF_RD_BOOK_PrevQ2'].clip(0, 20)\n",
    "\n",
    "test.loc[:,'NO_OF_RD_BOOK_PrevQ1'] = test['NO_OF_RD_BOOK_PrevQ1'].clip(0, 20)\n",
    "test.loc[:,'NO_OF_RD_BOOK_PrevQ2'] = test['NO_OF_RD_BOOK_PrevQ2'].clip(0, 20)\n",
    "\n",
    "train.loc[:,'FD_amt_diff'] = train['FD_AMOUNT_BOOK_PrevQ1'] - train['FD_AMOUNT_BOOK_PrevQ2']\n",
    "test.loc[:,'FD_amt_diff'] = test['FD_AMOUNT_BOOK_PrevQ1'] - test['FD_AMOUNT_BOOK_PrevQ2']\n",
    "\n",
    "train.loc[:,'DM_amt_diff'] = train['Dmat_Investing_PrevQ1'] - train['Dmat_Investing_PrevQ2']\n",
    "train.loc[:,'MF_amt_diff'] = train['Total_Invest_in_MF_PrevQ1'] - train['Total_Invest_in_MF_PrevQ2']\n",
    "\n",
    "test.loc[:,'DM_amt_diff'] = test['Dmat_Investing_PrevQ1'] - test['Dmat_Investing_PrevQ2']\n",
    "test.loc[:,'MF_amt_diff'] = test['Total_Invest_in_MF_PrevQ1'] - test['Total_Invest_in_MF_PrevQ2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Credit to Debit ratios\n",
    "\n",
    "train.loc[:, \"C_D_prev1_ratio\"] = train[\"C_prev1\"]/(1+train[\"D_prev1\"])\n",
    "test.loc[:, \"C_D_prev1_ratio\"] = test[\"C_prev1\"]/(1+test[\"D_prev1\"])\n",
    "\n",
    "train.loc[:, \"C_D_prev2_ratio\"] = train[\"C_prev2\"]/(1+ train[\"D_prev2\"])\n",
    "test.loc[:, \"C_D_prev2_ratio\"] = test[\"C_prev2\"]/(1+ test[\"D_prev2\"])\n",
    "\n",
    "train.loc[:, \"C_D_prev3_ratio\"] = train[\"C_prev3\"]/(1+train[\"D_prev3\"])\n",
    "test.loc[:, \"C_D_prev3_ratio\"] = test[\"C_prev3\"]/(1+test[\"D_prev3\"])\n",
    "\n",
    "train.loc[:, \"C_D_prev4_ratio\"] = train[\"C_prev4\"]/(1+train[\"D_prev4\"])\n",
    "test.loc[:, \"C_D_prev4_ratio\"] = test[\"C_prev4\"]/(1+test[\"D_prev4\"])\n",
    "\n",
    "train.loc[:, \"C_D_prev5_ratio\"] = train[\"C_prev5\"]/(1+train[\"D_prev5\"])\n",
    "test.loc[:, \"C_D_prev5_ratio\"] = test[\"C_prev5\"]/(1+test[\"D_prev5\"])\n",
    "\n",
    "train.loc[:, \"C_D_prev6_ratio\"] = train[\"C_prev6\"]/(1+train[\"D_prev6\"])\n",
    "test.loc[:, \"C_D_prev6_ratio\"] = test[\"C_prev6\"]/(1+test[\"D_prev6\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_periods = [\"prev1\", \"prev2\", \"prev3\", \"prev4\", \"prev5\", \"prev6\"]\n",
    "useful_channel = [\"CNR_\", \"BAL_\", \"EOP_\"]\n",
    "useful_cr_amb = [\"CR_AMB_Prev1\", \"CR_AMB_Prev2\", \"CR_AMB_Prev3\", \"CR_AMB_Prev4\", \"CR_AMB_Prev5\", \"CR_AMB_Prev6\"]\n",
    "diff_channel_C_columns = [\"count_C_\", \"COUNT_BRANCH_C_\", \"custinit_CR_cnt_\"]\n",
    "diff_channel_D_columns = [\"count_D_\", \"COUNT_ATM_D_\", \"COUNT_BRANCH_D_\", \"COUNT_IB_D_\", \"custinit_DR_cnt_\"]\n",
    "useful_C_channel = [\"BRANCH_C_\", \"custinit_CR_amt_\"]\n",
    "useful_D_channel = [\"ATM_D_\", \"BRANCH_D_\", \"IB_D_\", \"POS_D_\", \"custinit_DR_amt_\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_feats_imp = []\n",
    "for d in useful_channel:\n",
    "    cols = []\n",
    "    for t in time_periods:\n",
    "        cols.append(d+t)\n",
    "    a = \"Total_\"+d\n",
    "    train.loc[:, a] = np.average(train[cols], axis = 1, weights=[0.5, 0.25, 0.1, 0.1, 0.05 ,0])\n",
    "    test.loc[:, a] = np.average(test[cols], axis = 1, weights=[0.5, 0.25, 0.1, 0.1, 0.05 ,0])\n",
    "    new_feats_imp.append(a)\n",
    "\n",
    "new_feats_imp.append(\"Total_CR_AMB_\")\n",
    "train.loc[:, \"Total_CR_AMB_\"] = np.average(train[useful_cr_amb], axis = 1, weights=[0.5, 0.25, 0.1, 0.1, 0.05 ,0])\n",
    "test.loc[:, \"Total_CR_AMB_\"] = np.average(test[useful_cr_amb], axis = 1, weights=[0.5, 0.25, 0.1, 0.1, 0.05 ,0])\n",
    "\n",
    "new_feats_cnt = []\n",
    "for d in diff_channel_C_columns:\n",
    "    cols = []\n",
    "    for t in time_periods:\n",
    "        cols.append(d+t)\n",
    "    a = \"Total_\"+d\n",
    "    train.loc[:, a] = np.average(train[cols], axis = 1, weights=[0.3, 0.25, 0.2, 0.15, 0.1 ,0.1])\n",
    "    test.loc[:, a] = np.average(test[cols], axis = 1, weights=[0.3, 0.25, 0.2, 0.15, 0.1 ,0.1])\n",
    "    new_feats_cnt.append(a)\n",
    "for d in diff_channel_D_columns:\n",
    "    cols = []\n",
    "    for t in time_periods:\n",
    "        cols.append(d+t)\n",
    "    a = \"Total_\"+d\n",
    "    train.loc[:, a] = np.average(train[cols], axis = 1, weights=[0.3, 0.25, 0.2, 0.15, 0.1 ,0.1])\n",
    "    test.loc[:, a] = np.average(test[cols], axis = 1, weights=[0.3, 0.25, 0.2, 0.15, 0.1 ,0.1])\n",
    "    new_feats_cnt.append(a)\n",
    "\n",
    "new_feats_amt = []\n",
    "for d in useful_C_channel:\n",
    "    cols = []\n",
    "    for t in time_periods:\n",
    "        cols.append(d+t)\n",
    "    a = \"Total_\"+d\n",
    "    train.loc[:, a] = np.average(train[cols], axis = 1, weights=[0.3, 0.25, 0.2, 0.15, 0.1 ,0.1])\n",
    "    test.loc[:, a] = np.average(test[cols], axis = 1, weights=[0.3, 0.25, 0.2, 0.15, 0.1 ,0.1])\n",
    "    new_feats_amt.append(a)\n",
    "for d in useful_C_channel:\n",
    "    cols = []\n",
    "    for t in time_periods:\n",
    "        cols.append(d+t)\n",
    "    a = \"Total_\"+d\n",
    "    train.loc[:, a] = np.average(train[cols], axis = 1, weights=[0.3, 0.25, 0.2, 0.15, 0.1 ,0.1])\n",
    "    test.loc[:, a] = np.average(test[cols], axis = 1, weights=[0.3, 0.25, 0.2, 0.15, 0.1 ,0.1])\n",
    "    new_feats_amt.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "likeli_feats = [f for f in train.columns if '_likelihood' in f]\n",
    "new_feats = ['CR_mean_drop', 'CR_std_drop', 'EOP_mean_drop', 'EOP_std_drop', 'CR_sum_drop',\n",
    "            'EOB_rat1', 'CR_rat1', 'bal_rats', 'EOP_prev1log', 'brn_bal', 'zip_bal',\n",
    "            'brn_churn', 'zip_churn','bal_decline6', 'bal_decline5', 'bal_decline5',\n",
    "            'bal_decline3','bal_decline2', 'EOB_rat2', 'CR_rat2', 'debits_std', \n",
    "             'debits_mean', 'debit1_rat', 'EOB_rat1qcut', 'EOB_prev1qcut',\n",
    "            'acc_prem_close', 'acc_prem_close_sum', 'loan_close_num', 'growth_close_num',\n",
    "            'loan_live', 'loan_flag_sum1', 'loan_flag_sum2',\n",
    "            'FD_amt_diff', 'DM_amt_diff', 'MF_amt_diff',  'FD_Q1_Q2_diffabs', \"C_D_prev1_ratio\",\n",
    "            \"C_D_prev2_ratio\", \"C_D_prev3_ratio\", \"C_D_prev4_ratio\" ,\"C_D_prev5_ratio\", \"C_D_prev6_ratio\"]\n",
    "all_feats = num_feats + cat_cols + likeli_feats + new_feats + new_feats_imp + new_feats_cnt + new_feats_amt\n",
    "X = train[all_feats]\n",
    "X_test = test[all_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train[all_feats]\n",
    "y = train[\"Responders\"]\n",
    "X_test = test[all_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb.LGBMClassifier.predict_proba_corr = predict_proba_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize classifiers\n",
    "#lgb1 = lgb.LGBMClassifier(n_estimators=1200, \n",
    "#                          learning_rate=0.02, \n",
    "#                          max_depth=4, \n",
    "#                          num_leaves=15,\n",
    "#                          min_child_samples=200, \n",
    "#                          verbose=10, \n",
    "#                          colsample_bytree=0.7, \n",
    "#                          subsample=0.7, \n",
    "#                          random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up hyperparameter space for lightgbms\n",
    "def optimize_lightgbm(est, X, y, X_test, cvlist, save_path=\"../utility/\"):\n",
    "    space  = [(500, 1500),                           # n_estimators\n",
    "              (100, 400),                              # num_leaves\n",
    "              (0.3, 0.9),                            # colsample_bytree\n",
    "              (0.6, 1),                            # subsample\n",
    "              (5, 200),                             # min_child_samples\n",
    "              (1, 20)]                               # min_child_weight\n",
    "\n",
    "    def objective(params):\n",
    "        n_estimators, num_leaves, colsample_bytree, subsample, min_child_samples, min_child_weight = params\n",
    "        lgb_params = {\n",
    "        'n_estimators': n_estimators,\n",
    "        'num_leaves': num_leaves,\n",
    "        'colsample_bytree': colsample_bytree,\n",
    "        'subsample': subsample,\n",
    "        'min_child_samples': min_child_samples,\n",
    "        'min_child_weight': min_child_weight \n",
    "        }\n",
    "        print(\"parameters...................\",params)\n",
    "        preds = cross_val_predict(est.set_params(**lgb_params), X, y, cv=cvlist, verbose=1, method='predict_proba_corr')\n",
    "        print(\"score........................\",eval_top(y, preds))\n",
    "        preds_test = est.set_params(**lgb_params).fit(X, y).predict_proba_corr(X_test)\n",
    "        preds_dict = {'params':lgb_params, 'train_preds': preds, 'test_preds':preds_test}\n",
    "        filepath = os.path.join(save_path, str(time.time()))\n",
    "        with open(filepath, \"wb\") as f:\n",
    "            pickle.dump(preds_dict, f)\n",
    "        print(\"Saved..............:\", filepath)\n",
    "        return -1 * eval_top(y, preds)\n",
    "\n",
    "    res = gp_minimize(objective,                  # the function to minimize\n",
    "                      space,                          # the bounds on each dimension of x\n",
    "                      acq_func=\"EI\",                  # the acquisition function\n",
    "                      n_calls=20,                     # the number of evaluations of f \n",
    "                      n_random_starts=5,             # the number of random initialization points\n",
    "                      random_state=123,\n",
    "                     verbose=True) \n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing optimization for lgb\n",
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "parameters................... [1196, 186, 0.4361108721385219, 0.82052590763315658, 145, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 24.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score........................ 0.680252239008\n",
      "Saved..............: ../utility/1509908563.325094\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 1794.3550\n",
      "Function value obtained: -0.6803\n",
      "Current minimum: -0.6803\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "parameters................... [1481, 305, 0.58855914089061667, 0.7568470072776603, 72, 15]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-8b83e953ebf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Performing optimization for lgb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mres_lgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize_lightgbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcvlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#filename = 'skopt' + '_'.join([st[0] for st in .steps]) + '.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#dump(res_pipe1_onehot_lgb, filename)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-a2289f6bf964>\u001b[0m in \u001b[0;36moptimize_lightgbm\u001b[0;34m(est, X, y, X_test, cvlist, save_path)\u001b[0m\n\u001b[1;32m     35\u001b[0m                       \u001b[0mn_random_starts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;31m# the number of random initialization points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                       \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                      verbose=True) \n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abk0005/anaconda3/lib/python3.6/site-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         callback=callback, n_jobs=n_jobs)\n\u001b[0m",
      "\u001b[0;32m/Users/abk0005/anaconda3/lib/python3.6/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# no need to fit a model on the last iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mfit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_calls\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-a2289f6bf964>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     19\u001b[0m         }\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"parameters...................\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mlgb_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcvlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'predict_proba_corr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"score........................\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_top\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mpreds_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mlgb_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba_corr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abk0005/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    399\u001b[0m     prediction_blocks = parallel(delayed(_fit_and_predict)(\n\u001b[1;32m    400\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method)\n\u001b[0;32m--> 401\u001b[0;31m         for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;31m# Concatenate the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abk0005/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abk0005/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abk0005/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abk0005/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abk0005/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abk0005/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abk0005/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abk0005/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abk0005/anaconda3/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    541\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m                                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abk0005/anaconda3/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    389\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abk0005/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    199\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abk0005/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1414\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1415\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1416\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1417\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"Performing optimization for lgb\")\n",
    "res_lgb = optimize_lightgbm(lgb.LGBMClassifier(learning_rate=0.02), X, y, X_test, cvlist)\n",
    "#filename = 'skopt' + '_'.join([st[0] for st in .steps]) + '.pkl'\n",
    "#dump(res_pipe1_onehot_lgb, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
